# DÃ©tection de Fraude sur Cartes Bancaires

Projet de dÃ©tection de fraude Ã  la carte bancaire basÃ© sur le dataset public **Credit Card Fraud Detection** (Kaggle â€“ MLG ULB / Worldline).[web:2]

---

## ğŸ“Œ Description du projet

Ce projet vise Ã  construire un modÃ¨le de Machine Learning capable dâ€™identifier automatiquement les transactions frauduleuses Ã  partir de donnÃ©es rÃ©elles de cartes bancaires europÃ©ennes.[web:2][web:9]  
Le jeu de donnÃ©es est extrÃªmement dÃ©sÃ©quilibrÃ© (â‰ˆ 0,172 % de fraudes), ce qui en fait un cas typique de classification avec classes rares.[web:2]

---

## ğŸ—‚ï¸ Dataset

- Source : Kaggle â€“ *Credit Card Fraud Detection* (MLG ULB / Worldline).[web:2]  
- Nombre de transactions : 284â€¯807  
- Nombre de fraudes : 492 (â‰ˆ 0,172 %)  
- Variables :
  - `Time` : secondes depuis la premiÃ¨re transaction.
  - `Amount` : montant de la transaction.
  - `V1` Ã  `V28` : composantes issues dâ€™une PCA (donnÃ©es anonymisÃ©es).[web:2]
  - `Class` : cible binaire (0 = normal, 1 = fraude).

> Le fichier CSV nâ€™est pas inclus dans le dÃ©pÃ´t et doit Ãªtre tÃ©lÃ©chargÃ© directement depuis Kaggle.[web:20]

---

## ğŸ§¹ PrÃ©traitement des donnÃ©es

Principales Ã©tapes de prÃ©paration :  
- Suppression dâ€™Ã©ventuels doublons et contrÃ´le des valeurs manquantes.[web:2]  
- Standardisation de `Time` et `Amount` (centrage-rÃ©duction).[web:2]  
- Gestion du dÃ©sÃ©quilibre de classes avec :
  - **SMOTE** pour sur-Ã©chantillonner la classe fraude.[web:7]
  - `class_weight="balanced"` dans certains modÃ¨les pour pondÃ©rer la classe minoritaire.[web:7][web:9]

---

## ğŸ” Analyse exploratoire (EDA)

- Ã‰tude de la distribution des montants (`Amount`) et du temps (`Time`).[web:2]  
- Visualisation de la rÃ©partition des classes (fraude vs normal).[web:2]  
- Analyse de certaines composantes PCA (ex. `V12`, `V14`, `V17`) montrant des patterns associÃ©s aux fraudes.[web:1][web:3]

---

## ğŸ¤– ModÃ¨les utilisÃ©s

Plusieurs algorithmes de classification supervisÃ©e sont testÃ©sâ€¯:  
- **RÃ©gression logistique** (baseline).  
- **Random Forest** (modÃ¨le dâ€™arbres en ensemble, robuste au bruit).[web:5]  
- **XGBoost / LightGBM** (gradient boosting sur arbres, adaptÃ©s aux patterns rares et donnÃ©es dÃ©sÃ©quilibrÃ©es).[web:8]

Les modÃ¨les sont entraÃ®nÃ©s dans un pipeline intÃ©grant prÃ©traitement, gestion du dÃ©sÃ©quilibre et optimisation dâ€™hyperparamÃ¨tres.

---

## ğŸ“ˆ MÃ©triques dâ€™Ã©valuation

Lâ€™accuracy seule nâ€™est pas pertinente dans ce contexte dÃ©sÃ©quilibrÃ©.[web:9]  
Les mÃ©triques suivies sont :  
- **Recall** sur la classe fraude (prioritÃ© mÃ©tier).  
- **Precision** sur la classe fraude.  
- **F1-score**.  
- **Matrice de confusion**.  
- **ROC-AUC** et **Precisionâ€“Recall AUC**, plus informative lorsque la classe positive est rare.[web:9]

---

## ğŸ§  InterprÃ©tabilitÃ© & amÃ©liorations

Pistes dâ€™analyse et dâ€™amÃ©lioration :  
- Utilisation de **SHAP** pour interprÃ©ter les dÃ©cisions des modÃ¨les de type XGBoost / LightGBM.[web:8]  
- Exploration de modÃ¨les **deep learning** (autoencodeurs, LSTM) pour la dÃ©tection dâ€™anomalies et la prise en compte de la dimension temporelle.[web:4]  
- IntÃ©gration possible de nouvelles variables comportementales (device, localisation, historique client) dans un contexte rÃ©el.[web:6]

---

## ğŸ“¦ Installation

